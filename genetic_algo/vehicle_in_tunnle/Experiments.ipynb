{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The project experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FoV_Tunnel; from FoV_Tunnel import FoV; #FOV publisher\n",
    "import ctrnn\n",
    "import ea_tournament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from numpy import array as narr\n",
    "import time\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import copy\n",
    "\n",
    "import jupyternotify # For notifications in the browser\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent():\n",
    "    def __init__(self, pos, direc, \n",
    "                 retina_len = 100, retina_range=[-60,240], view_range=10):\n",
    "        #pos and direc currently correspond directly to \n",
    "            # camera_pos and camera_phi in FOV file.\n",
    "        # direc = camera_phi+pi/2\n",
    "        self.pos = narr(pos)\n",
    "        self.dir = direc\n",
    "        \n",
    "        # Subscribe to FOV\n",
    "        self.fov = FoV(retina_len, retina_range, view_range, verbose=False)\n",
    "        self.value = 0.\n",
    "        \n",
    "        \n",
    "    def _perceive(self):\n",
    "        # This function inquires for the environment's reaction to the current position of the agent.\n",
    "        \n",
    "        retinal_img = self.fov.update_retina(self.pos, self.dir-np.pi/2)\n",
    "        return retinal_img\n",
    "    \n",
    "    def _move_straight(self, step_size):\n",
    "        # step is a float\n",
    "        self.pos += step_size*narr([np.cos(self.dir), np.sin(self.dir)])\n",
    "    \n",
    "    def _rotate(self, dphi):\n",
    "        # dphi is in radian\n",
    "        self.dir += dphi\n",
    "        self.dir = self.dir %(2*np.pi)\n",
    "    \n",
    "    def act(self):\n",
    "        sensory_info = self._perceive() \n",
    "        # Relate sensory_info to action\n",
    "#         self._rotate(0.1) # For test, spiral movement @@\n",
    "        self._move_straight(0.9) #For test, spiral movement @@\n",
    "        # It might be better to move this line into the _perceive method.\n",
    "        self.pos, reward = env.response(self.pos) \n",
    "        self.value += reward\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class environment():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def response(*args):\n",
    "        # override it\n",
    "        return None\n",
    "\n",
    "class StraightTunnel(environment):\n",
    "    \n",
    "    def __init__(self, length, width, lseg_len=None):\n",
    "        # hyperparams\n",
    "        t_width = width; self.t_rad = t_width/2;\n",
    "        self.t_len = length\n",
    "        if lseg_len==None:\n",
    "            lseg_len = width/3.\n",
    "        nlseg = int(self.t_len/lseg_len)\n",
    "\n",
    "        self.obj_list = []\n",
    "        tag_ofs = 1\n",
    "        tag_amp = 0\n",
    "\n",
    "        for i in range(nlseg):\n",
    "            x1r=self.t_rad; x2r=self.t_rad;\n",
    "            x1l=-self.t_rad;x2l=-self.t_rad;\n",
    "            y1=i*lseg_len; y2=y1+lseg_len;\n",
    "            self.obj_list.append([[x1r, y1],[x2r, y2],int(tag_ofs+tag_amp*(i%2))])\n",
    "            self.obj_list.append([[x1l, y1],[x2l, y2],int(tag_ofs+tag_amp*(i%2))])\n",
    "            \n",
    "    def response(self, pos):\n",
    "        reward = 0\n",
    "        if pos[0] > self.t_rad:\n",
    "            pos[0] = 0.95*self.t_rad; reward -=1 #collision\n",
    "        if pos[0] < -self.t_rad:\n",
    "            pos[0] = -0.95*self.t_rad; reward -=1 #collision\n",
    "        \n",
    "        if pos[1] >= self.t_len or pos[1] < 0: # Reached one of the ends of the tunnel\n",
    "            reward =1\n",
    "        return (pos, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class agent_mass(agent):\n",
    "    \n",
    "    def __init__(self, genotype, pos, direc, \n",
    "                 retina_len = 3, dsr=1., angular_range=[0,180], distance_range=20):\n",
    "        #pos and direc currently correspond directly to \n",
    "            # camera_pos and camera_phi in FOV file.\n",
    "        # direc = camera_phi+pi/2\n",
    "        self.pos = narr(pos)\n",
    "        self.dir = direc\n",
    "        self.posold = copy.deepcopy(self.pos) # previous position is needed\n",
    "        \n",
    "        # Set the constants of the agent model\n",
    "        # wing_len, J, mass, b(velocity friction)\n",
    "        self.wing_l = 2e-3\n",
    "        self.inert = 5e6\n",
    "        self.mass = 5e-7\n",
    "        self.vfric = 1e-7\n",
    "        maxforce = 3e-4 \n",
    "        \n",
    "        # Subscribe to FOV\n",
    "        self.fov = FoV(retina_len, angular_range, distance_range, verbose=False)\n",
    "        self.value = 0. # For storing the rewards returned by environment\n",
    "        \n",
    "        # Brain\n",
    "#         self.dsr=dsr\n",
    "        self.nnsize = retina_len+4\n",
    "        self.nn = ctrnn.CTRNN(self.nnsize)\n",
    "        \n",
    "        # Set free parameters using the genotype\n",
    "        \n",
    "        # The free parameters of the model include:\n",
    "        # 0:retina_len => weights from retina to neurons => self.fov.retina_len \n",
    "        # retina_len:-7 (nnsize**2 + 2*nnsize) => between neurons=> n**2\n",
    "        # -7:-3 => motor gains from nn outputs to wings\n",
    "        # -3: => gains from wings to force and tau\n",
    "        # e.g. if we don't have any interneurons, the total number of params would be:\n",
    "            # nn \\size = 3+4 => len(genotype) = 3+ (49+14)+7 = 7\n",
    "        \n",
    "\n",
    "        # Set sensory neuron gains\n",
    "        self.gs = 2*narr(genotype[:self.fov.retina_len])\n",
    "        self.nn.setParameters(genotype[self.fov.retina_len:-7])\n",
    "            \n",
    "    # motoneuron to W => 4 (WRX, WRY, WLX, WLY) , should be positive [0,1]\n",
    "        self.gwrx = 0.5*(genotype[-7]+1)#*self.nn.Output[-1]\n",
    "        self.gwry = 0.5*(genotype[-6]+1)#*self.nn.Output[-2]\n",
    "        self.gwlx = 0.5*(genotype[-5]+1)#*self.nn.Output[-3]\n",
    "        self.gwly = 0.5*(genotype[-4]+1)#*self.nn.Output[-4]\n",
    "        \n",
    "        # gains from wing to force and torque => 3\n",
    "        force_interp = interp1d([-1,1],[0., maxforce]) \n",
    "        \n",
    "        self.gwfx = force_interp(genotype[-3])\n",
    "        self.gwfy = force_interp(genotype[-2])-5e-11\n",
    "        self.gwt = force_interp(genotype[-1])\n",
    "        #         \n",
    "                \n",
    "    def reset(self, pos, direc):\n",
    "        self.pos = narr(pos)\n",
    "        self.dir = direc\n",
    "        self.posold = copy.deepcopy(self.pos)\n",
    "        self.nn.reset()\n",
    "        self.value = 0.\n",
    "        self.fov.update_retina(self.pos, self.dir)\n",
    "        \n",
    "    \n",
    "    def _generate_force(self):\n",
    "        # Translate network output to future position (self.pos)\n",
    "        wrx = self.gwrx*self.nn.Output[-1]\n",
    "        wry = self.gwry*self.nn.Output[-2]\n",
    "        wlx = self.gwlx*self.nn.Output[-3]\n",
    "        wly = self.gwly*self.nn.Output[-4]\n",
    "        \n",
    "        fxa = self.gwfx*(wrx-wlx) #force generated towards the x-axis of the agent\n",
    "        fya = self.gwfy*(wry+wly) #force generated towards the y-axis of the agent\n",
    "        tz = self.gwt*self.wing_l*(wry-wly)\n",
    "        return fxa, fya, tz\n",
    "        \n",
    "        \n",
    "    def _movement(self, fxa, fya, tz):\n",
    "        #Translate force and torque to position and direction\n",
    "        posdot = self.pos - self.posold\n",
    "        \n",
    "        force = ( fxa*narr([np.cos(self.dir-np.pi/2), np.sin(self.dir-np.pi/2)]) \n",
    "                 +fya*narr([np.cos(self.dir),         np.sin(self.dir)]))\n",
    "        \n",
    "        vdot = force/self.mass - self.vfric*posdot\n",
    "\n",
    "        thetadot = self.inert*tz\n",
    "        \n",
    "        posdot += vdot *stepsize\n",
    "        \n",
    "        self.posold = self.pos.copy() #Apparently copy() is necessary\n",
    "\n",
    "        self.pos += posdot*stepsize   \n",
    "        self.dir += thetadot*stepsize\n",
    "    \n",
    "        \n",
    "        \n",
    "    def act(self, update_ret_flag=True):\n",
    "        if update_ret_flag:\n",
    "            ret_img = self._perceive()\n",
    "        else:\n",
    "            ret_img = self.fov.get_retina() #No retina updating\n",
    "        Input = np.dot(self.gs, ret_img)#np.zeros(nn.Size); Input[0] = sg*genotype[-1]*ctheta; Input[1] = sg*genotype[-2]*ctheta #Input = sg**ctheta*narr(genotype[-size:]); #\n",
    "        self.nn.step(stepsize, Input)\n",
    "        fxa, fya, tz = self._generate_force()\n",
    "\n",
    "        self._movement(fxa, fya, tz)\n",
    "        \n",
    "        # It might be better to move this line into the _perceive method.\n",
    "        self.pos, reward = env.response(self.pos) \n",
    "        self.value += reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the mass agent with random weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with the initial heading and position. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = StraightTunnel(6,1, lseg_len=1/3.)\n",
    "viewchange_thr = 0.01 #The amount of movement/rotation after which the retina is updated\n",
    "\n",
    "retina_len =3\n",
    "n_sensory = retina_len\n",
    "n_motor = 4\n",
    "n_bodydyn = 3\n",
    "n_neurons = n_sensory+n_motor\n",
    "n_params = retina_len +n_neurons**2+2*n_neurons +n_motor +n_bodydyn\n",
    "tgenotype = np.random.rand(n_params)\n",
    "init_heading = np.pi/2\n",
    "init_pos = [0.1,2.9]\n",
    "\n",
    "# Global variables used\n",
    "stepsize = 0.001\n",
    "duration = 3.10\n",
    "\n",
    "\n",
    "agent2 = agent_mass(tgenotype, init_pos, init_heading,\n",
    "               retina_len = retina_len, angular_range=[0,180], distance_range=20)\n",
    "\n",
    "obj_list = env.obj_list    \n",
    "agent2.fov.add_env_obj(obj_list) # Add all environment objects to fov.\n",
    "# Warning: This is weird and inefficient. should be changed later.\n",
    "\n",
    "\n",
    "time1 = np.arange(0.0,duration,stepsize)\n",
    "fig,ax=plt.subplots(5, 1)\n",
    "t1 = time.time()\n",
    "\n",
    "posv = np.zeros((time1.shape[0],2))\n",
    "dirv = np.zeros_like(time1)\n",
    "\n",
    "i=0\n",
    "step=0\n",
    "update_ret_flag = True; viewchange_rec = 0.\n",
    "for t in time1:\n",
    "    dirold = agent2.dir #the previous direction is used later\n",
    "    agent2.act(update_ret_flag)\n",
    "    posv[step,:] = agent2.pos\n",
    "    dirv[step] = agent2.dir\n",
    "    viewchange_rec += abs(agent2.dir - dirold)+np.linalg.norm(agent2.pos - agent2.posold)\n",
    "\n",
    "    if viewchange_rec> viewchange_thr:\n",
    "        update_ret_flag = True\n",
    "        viewchange_rec = 0\n",
    "    else:\n",
    "        update_ret_flag = False\n",
    "    if int(t/stepsize)%(int(len(time1)/5)+1) == 0:\n",
    "        print(\"Retina = \", agent2.fov.get_retina())\n",
    "        print(\"Neuron outputs = \", agent2.nn.Output)\n",
    "        ax[i].imshow(narr([agent2.fov.retina,]))\n",
    "        \n",
    "        i+=1\n",
    "    step +=1\n",
    "print(\"Elapsed Time: \", time.time() - t1)\n",
    "plt.figure()\n",
    "plt.plot(posv)\n",
    "plt.title('position (x: blue, y: orange, direction: green)')\n",
    "plt.plot(dirv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it in a fitness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunnel_len = 6\n",
    "env = StraightTunnel(tunnel_len,1, lseg_len=1/3.)\n",
    "viewchange_thr = 0.02 #The amount of movement/rotation after which the retina is updated\n",
    "\n",
    "retina_len =3\n",
    "n_sensory = retina_len\n",
    "n_motor = 4\n",
    "n_bodydyn = 3\n",
    "n_neurons = n_sensory+n_motor\n",
    "n_params = retina_len +n_neurons**2+2*n_neurons +n_motor +n_bodydyn\n",
    "agent_gene = np.random.rand(n_params)\n",
    "init_heading = np.pi/2\n",
    "init_pos = [0.1,2.9]\n",
    "\n",
    "# Global variables used\n",
    "stepsize = 0.001\n",
    "duration = 5.10\n",
    "\n",
    "def evalgenotype(agent_gene):\n",
    "    \n",
    "    agent2 = agent_mass(agent_gene, init_pos, init_heading,\n",
    "               retina_len = retina_len, angular_range=[0,180], distance_range=10)\n",
    "    obj_list = env.obj_list    \n",
    "    agent2.fov.add_env_obj(obj_list) # Add all environment objects to fov.\n",
    "\n",
    "\n",
    "    time1 = np.arange(0.0,duration,stepsize)\n",
    "    t1 = time.time()\n",
    "    \n",
    "    headings = narr([np.pi/4, np.pi/2, np.pi])\n",
    "    fit_i = np.zeros_like(headings)\n",
    "    \n",
    "    i=0\n",
    "    for h1 in headings:\n",
    "        agent2.reset(init_pos, h1)\n",
    "\n",
    "#     step=0\n",
    "        update_ret_flag = True; viewchange_val = 0.\n",
    "        for t in time1:\n",
    "            dirold = agent2.dir\n",
    "            agent2.act(update_ret_flag) # *** The main line where the agent pereceives and acts\n",
    "            if agent2.value !=0: #If hit the wall or came out of the tunnel, finish simulation\n",
    "                break\n",
    "            viewchange_val += abs(agent2.dir - dirold)+np.linalg.norm(agent2.pos - agent2.posold)\n",
    "\n",
    "            if viewchange_val>viewchange_thr:\n",
    "                update_ret_flag = True\n",
    "                viewchange_val = 0\n",
    "            else:\n",
    "                update_ret_flag = False\n",
    "        fit_i[i] = np.linalg.norm(agent2.pos - init_pos)/(0.5*tunnel_len)\n",
    "        i+=1\n",
    "    return float(np.mean(fit_i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization using EA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genesize = n_params\n",
    "popsize = 50 #3*genesize\n",
    "recombProb = 0.5\n",
    "mutatProb = 1.5*(1/genesize) #0.1\n",
    "generations = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = ea_tournament.EA(evalgenotype, popsize, genesize, recombProb, mutatProb, \"R\")\n",
    "# ga = ea_tournament.EA(evalgenotype_linear, popsize, genesize, recombProb, mutatProb, \"R\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 30 minutes to run for popsize = 50, generations = 50\n",
    "t0 = time.time()\n",
    "for i in range(0, generations):\n",
    "    ga.generation()\n",
    "    print(\"Generation \", i, \": Best Fitness = \", ga.bestHistory[-1])\n",
    "print(\"Elapsed Time = \", time.time()-t0)\n",
    "ga.showFitness()\n",
    "\n",
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "af,bf,bi = ga.fitStats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Fitness = \", bf)\n",
    "print(\"Best Individual (in EA space) = \")\n",
    "bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunnel_len = 6\n",
    "env = StraightTunnel(tunnel_len,1, lseg_len=1/3.)\n",
    "viewchange_thr = 0.02\n",
    "\n",
    "retina_len =3\n",
    "n_sensory = retina_len\n",
    "n_motor = 4\n",
    "n_bodydyn = 3\n",
    "n_neurons = n_sensory+n_motor\n",
    "n_params = retina_len +n_neurons**2+2*n_neurons +n_motor +n_bodydyn\n",
    "agent_gene = np.random.rand(n_params)\n",
    "init_heading = np.pi/2\n",
    "init_pos = [0.1,2.9]\n",
    "\n",
    "# Global variables used\n",
    "stepsize = 0.001\n",
    "duration = 5.10\n",
    "\n",
    "agent2 = agent_mass(bi, init_pos, init_heading,\n",
    "           retina_len = retina_len, angular_range=[0,180], distance_range=10)\n",
    "obj_list = env.obj_list    \n",
    "agent2.fov.add_env_obj(obj_list) # Add all environment objects to fov.\n",
    " \n",
    "time1 = np.arange(0.0,duration,stepsize)\n",
    "t1 = time.time()\n",
    "\n",
    "headings = narr([np.pi/4, np.pi/2, np.pi])\n",
    "\n",
    "outputs = np.zeros((len(headings), len(time1),n_neurons))\n",
    "poshist = np.zeros((len(headings), len(time1), 2))\n",
    "dirhist = np.zeros((len(headings), len(time1)))\n",
    "\n",
    "i=0\n",
    "for h1 in headings:\n",
    "    agent2.reset(init_pos, h1)\n",
    "\n",
    "    step=0\n",
    "    update_ret_flag = True; viewchange_rec = 0.\n",
    "    for t in time1:\n",
    "        dirold = agent2.dir\n",
    "        agent2.act(update_ret_flag)\n",
    "#         posv[step,:] = agent2.pos\n",
    "#         dirv[step] = agent2.dir\n",
    "        if agent2.value !=0: #If hit the wall or came out of the tunnel, finish simulation\n",
    "            print('Trial ended with reward ', agent2.value)\n",
    "            outputs[i, step:, :] = np.nan\n",
    "            poshist[i, step:, :] = np.nan\n",
    "            dirhist[i, step:] = np.nan\n",
    "            break\n",
    "        viewchange_rec += abs(agent2.dir - dirold)+np.linalg.norm(agent2.pos - agent2.posold)\n",
    "\n",
    "        if viewchange_rec>viewchange_thr:\n",
    "            update_ret_flag = True\n",
    "            viewchange_rec = 0\n",
    "        else:\n",
    "            update_ret_flag = False\n",
    "            \n",
    "        outputs[i, step, :] = agent2.nn.Output\n",
    "        poshist[i, step, :] = agent2.pos\n",
    "        dirhist[i, step] = agent2.dir\n",
    "        step +=1\n",
    "    i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcp0 = pd.DataFrame({'X': poshist[0,:,0],\n",
    "                    'Y': poshist[0,:,1],\n",
    "                    'Heading': dirhist[0,:]})\n",
    "\n",
    "dtindex = pd.to_datetime(time1, unit='s')\n",
    "dfcp0.index = dtindex\n",
    "dfcp0 = dfcp0.asfreq('1ms')\n",
    "\n",
    "dfcp1 = pd.DataFrame({'X': poshist[1,:,0],\n",
    "                    'Y': poshist[1,:,1],\n",
    "                    'Heading': dirhist[1,:]})\n",
    "\n",
    "dfcp2 = pd.DataFrame({'X': poshist[2,:,0],\n",
    "                    'Y': poshist[2,:,1],\n",
    "                    'Heading': dirhist[2,:]})\n",
    "\n",
    "\n",
    "dfcp1.index = dtindex\n",
    "dfcp1 = dfcp1.asfreq('1ms')\n",
    "\n",
    "\n",
    "# dfnn0 = pd.DataFrame({'Nrn 0':outputs[0,:,0]})\n",
    "# for i in range(1,n_neurons):\n",
    "#     dfnn0['Nrn '+str(i)] = outputs[0,:,i]\n",
    "# dfnn0.index = dtindex\n",
    "# dfnn0 = dfnn0.asfreq('1ms')\n",
    "\n",
    "\n",
    "# dfnn1 = pd.DataFrame({'Neuron 0':outputs[1,:,0]})\n",
    "# for i in range(1,n_neurons):\n",
    "#     dfnn1['Neuron '+str(i)] = outputs[1,:,i]\n",
    "# dfnn1.index = dtindex\n",
    "# dfnn1 = dfnn1.asfreq('1ms')\n",
    "\n",
    "# dfnn2 = pd.DataFrame({'Neuron 0':outputs[2,:,0]})\n",
    "# for i in range(1,n_neurons):\n",
    "#     dfnn2['Neuron '+str(i)] = outputs[2,:,i]\n",
    "# dfnn2.index = dtindex\n",
    "# dfnn2 = dfnn1.asfreq('1ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "    \n",
    "for item in agent2.fov.obj_list:\n",
    "    line = narr([item[0],item[1]])\n",
    "    ax.set_facecolor('w')\n",
    "    ax.plot(line[:,0],line[:,1],c='k')\n",
    "ax.axis('equal')\n",
    "    \n",
    "ax.scatter(init_pos[0],init_pos[1], c='r')\n",
    "ax.plot(dfcp0['X'], dfcp0['Y'] , '--', label='Trial #1')\n",
    "ax.plot(dfcp1['X'], dfcp1['Y'] , '--', label='Trial #2')\n",
    "ax.plot(dfcp2['X'], dfcp2['Y'] , '--', label='Trial #3')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create figure 1a for the report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, -1.3, 'Retinal Image')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "camera_pos = [0.1, 2.9]; camera_phi = np.pi/2\n",
    "agent2.reset(camera_pos, camera_phi)\n",
    "agent2.fov.update_retina(agent2.pos, agent2.dir-np.pi/2)\n",
    "\n",
    "cell_angles = np.rad2deg(agent2.fov.get_cell_angles())\n",
    "\n",
    "fig_len=10\n",
    "gs = gridspec.GridSpec(2, 1,\n",
    "                       height_ratios=[fig_len, 1])#@@\n",
    "\n",
    "ax = plt.subplot(gs[0]) #@@\n",
    "\n",
    "# Plot the camera\n",
    "ax.scatter(camera_pos[0],camera_pos[1],c='r')\n",
    "arrow_size = 0.03*fig_len;\n",
    "arrow_vec = arrow_size* narr([np.cos(camera_phi), np.sin(camera_phi)])\n",
    "ax.arrow(camera_pos[0],camera_pos[1], arrow_vec[0],arrow_vec[1],**{'color':'r', 'shape':'full'})\n",
    "\n",
    "tag_it = (item[2] for item in agent2.fov.obj_list)\n",
    "first_it, second_it = itertools.tee(tag_it,2)\n",
    "norm = matplotlib.colors.Normalize(vmin=min(first_it), vmax=max(second_it), clip=False)\n",
    "mapper = cm.ScalarMappable(norm=norm, cmap=cm.Greys)\n",
    "    \n",
    "for item in agent2.fov.obj_list:\n",
    "    line = narr([item[0],item[1]])\n",
    "    ax.set_facecolor('w')\n",
    "    ax.plot(line[:,0],line[:,1],c='k')\n",
    "ax.axis('equal')\n",
    "\n",
    "\n",
    "cmap = mapper.cmap; cmap.set_under(color='w', alpha=None)\n",
    "\n",
    "tretina = agent2.fov.retina\n",
    "ax2 = plt.subplot(gs[1])#@@\n",
    "ax2.imshow([tretina,], cmap=mapper.cmap)#, norm=norm)\n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.axes.get_yaxis().set_visible(False)\n",
    "ax2.set_title('Retinal Image', y=-1.3)\n",
    "# if cell_angles is not None:\n",
    "#     label_pos = np.arange(0,tretina.size, fig_len*2)\n",
    "#     cell_labels = cell_angles[0:tretina.size:fig_len*2]\n",
    "#     cell_labels = [ '%.f' % elem for elem in cell_labels]\n",
    "#     ax2.set_xticks(label_pos)\n",
    "#     ax2.set_xticklabels(cell_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Network Parameters and Topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the topology using pygraphviz\n",
    "import pygraphviz as pgv\n",
    "from itertools import combinations \n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import datetime\n",
    "from IPython.display import SVG, display\n",
    "%display inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = agent2.nn\n",
    "\n",
    "G1=pgv.AGraph(strict=False,directed=True)\n",
    "for i in range(nn.Size):\n",
    "    G1.add_node(str(i), xlabel='b='+(\"%.f\" %nn.Bias[i]))\n",
    "for node1 in G1.nodes():\n",
    "    for node2 in G1.nodes():\n",
    "        cweight = nn.Weight[int(node1),int(node2)]\n",
    "        if cweight<0:\n",
    "            ccolor = 'red'\n",
    "        else:\n",
    "            ccolor = 'green'\n",
    "        G1.add_edge(node1,node2, penwidth=abs(cweight/15), color=ccolor)\n",
    "#         G1.add_edge(node1,node2, weight=abs(cweight/15), color=ccolor)\n",
    "\n",
    "for i in range(retina_len):\n",
    "    G1.add_node('Retina'+str(i), style=\"filled\", fillcolor='yellow')\n",
    "    G1.add_edge('Retina'+str(i),str(i), label=\"%.f\" % (agent2.gs[i]))\n",
    "\n",
    "G1.add_node('Wing RX', style=\"filled\", fillcolor='cyan')\n",
    "G1.add_edge('3', 'Wing RX', label=\"%.f\" % (agent2.gwrx))\n",
    "G1.add_node('Wing RY', style=\"filled\", fillcolor='cyan')\n",
    "G1.add_edge('4', 'Wing RY', label=\"%.f\" % (agent2.gwry))\n",
    "G1.add_node('Wing LX', style=\"filled\", fillcolor='cyan')\n",
    "G1.add_edge('5', 'Wing LX', label=\"%.f\" % (agent2.gwlx))\n",
    "G1.add_node('Wing LY', style=\"filled\", fillcolor='cyan')\n",
    "G1.add_edge('6', 'Wing LY', label=\"%.f\" % (agent2.gwly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1.layout(prog='circo')\n",
    "datinow = datetime.datetime.now()\n",
    "# anim.save('polecart_c_sample'+str(int(time.time()%100))+'.mp4',dpi=150)\n",
    "G1.draw('network'+datinow.strftime(\"%b%d-%H-%M\")+'.svg')\n",
    "# display(SVG(url='test_net2.svg'))\n",
    "# fig, ax = plt.subplots(figsize=(4, 4))\n",
    "# ax.imshow(mpimg.imread('pcnet3.svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
